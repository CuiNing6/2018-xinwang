{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 160)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../data/train_xy.csv')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 159)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('../data/train_x.csv')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 103)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv_feature = ['x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_8', 'x_9', 'x_10', 'x_11', 'x_12', 'x_13', 'x_14', 'x_15', 'x_16', 'x_17', 'x_18', 'x_19', 'x_20', 'x_21', 'x_22', 'x_23', 'x_24', 'x_25', 'x_26', 'x_27', 'x_28', 'x_29', 'x_30', 'x_31', 'x_32', 'x_33', 'x_34', 'x_35', 'x_36', 'x_37', 'x_38', 'x_39', 'x_40', 'x_41', 'x_42', 'x_43', 'x_44', 'x_45', 'x_46', 'x_47', 'x_48', 'x_50', 'x_51', 'x_52', 'x_53', 'x_54', 'x_55', 'x_56', 'x_57', 'x_58', 'x_59', 'x_60', 'x_61', 'x_62', 'x_63', 'x_64', 'x_65', 'x_66', 'x_67', 'x_68', 'x_69', 'x_70', 'x_71', 'x_72', 'x_73', 'x_74', 'x_75', 'x_76', 'x_77', 'x_78', 'x_79', 'x_80', 'x_81', 'x_82', 'x_83', 'x_84', 'x_85', 'x_86', 'x_87', 'x_88', 'x_90', 'x_97', 'x_98', 'x_99', 'x_100', 'x_101', 'x_139', 'x_140', 'x_141', 'x_142', 'x_143', 'x_144', 'x_149', 'x_150', 'x_153', 'x_154', 'x_155', 'x_157']\n",
    "x_train = train[iv_feature]\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 103)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv_feature = ['x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_8', 'x_9', 'x_10', 'x_11', 'x_12', 'x_13', 'x_14', 'x_15', 'x_16', 'x_17', 'x_18', 'x_19', 'x_20', 'x_21', 'x_22', 'x_23', 'x_24', 'x_25', 'x_26', 'x_27', 'x_28', 'x_29', 'x_30', 'x_31', 'x_32', 'x_33', 'x_34', 'x_35', 'x_36', 'x_37', 'x_38', 'x_39', 'x_40', 'x_41', 'x_42', 'x_43', 'x_44', 'x_45', 'x_46', 'x_47', 'x_48', 'x_50', 'x_51', 'x_52', 'x_53', 'x_54', 'x_55', 'x_56', 'x_57', 'x_58', 'x_59', 'x_60', 'x_61', 'x_62', 'x_63', 'x_64', 'x_65', 'x_66', 'x_67', 'x_68', 'x_69', 'x_70', 'x_71', 'x_72', 'x_73', 'x_74', 'x_75', 'x_76', 'x_77', 'x_78', 'x_79', 'x_80', 'x_81', 'x_82', 'x_83', 'x_84', 'x_85', 'x_86', 'x_87', 'x_88', 'x_90', 'x_97', 'x_98', 'x_99', 'x_100', 'x_101', 'x_139', 'x_140', 'x_141', 'x_142', 'x_143', 'x_144', 'x_149', 'x_150', 'x_153', 'x_154', 'x_155', 'x_157']\n",
    "x_test = test[iv_feature]\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c254adf9e8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPkAAADuCAYAAAD7nKGzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['y'].value_counts().plot.pie(autopct = '%1.2f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 103)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.concat([x_train,x_test])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = train['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(96,158):\n",
    "    col = 'x'+'_'+str(i)\n",
    "    if col in x.columns.values:\n",
    "        dummies_df = pd.get_dummies(x[col]).rename(columns=lambda x: col + str(x))\n",
    "        x = pd.concat([x, dummies_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 170)\n",
      "(10000, 170)\n"
     ]
    }
   ],
   "source": [
    "train_X = x[0:15000]\n",
    "test_X = x[15000:25000]\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model #泛型模型\n",
    "from keras.layers import Dense, Input\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(data_):\n",
    "    idx_1 = data_[data_['label']==0].index\n",
    "    idx_2 = data_[data_['label']==1].index\n",
    "    nb_1 = len(data_.loc[idx_1])\n",
    "    nb_2 = len(data_.loc[idx_2])\n",
    "#     print(nb_1)\n",
    "#     print(nb_2)\n",
    "    idx_list_1 = list(idx_1)\n",
    "    idx_list_2 = list(idx_2)\n",
    "    train_x1 = data_.loc[idx_list_1]\n",
    "    train_x2 = data_.loc[idx_list_2]\n",
    "#     print(train_x1.shape)\n",
    "#     print(train_x2.shape)\n",
    "    return train_x1,train_x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resample_data(data, number):\n",
    "    idx_1 = data.index\n",
    "    nb_1 = len(idx_1)\n",
    "#     print(nb_1)\n",
    "#     number = int(nb_1 * rate)\n",
    "    idx_1_sub = np.random.choice(idx_1, number)\n",
    "#     print(idx_1_sub)\n",
    "    nb_2 = len(data.loc[idx_1_sub])\n",
    "#     print(nb_2)\n",
    "    idx_list_1 = list(idx_1_sub)\n",
    "    train_1 = data.loc[idx_1_sub]\n",
    "#     print(train_1.shape)\n",
    "    return train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 170)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_val,y_train,y_val= train_test_split(train_X,Y_train,test_size=0.2,random_state=2)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12000, 171)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = X_train\n",
    "xx['label'] = y_train\n",
    "\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11442, 171)\n",
      "(558, 171)\n"
     ]
    }
   ],
   "source": [
    "train_x1, train_x2 = split_data(xx)\n",
    "print(train_x1.shape)\n",
    "print(train_x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = resample_data(train_x1, 10000)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11442, 170)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_x1.drop(['label'],axis=1)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(558, 170)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data1 = train_x2.drop(['label'],axis=1)\n",
    "train_data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>x_10</th>\n",
       "      <th>x_11</th>\n",
       "      <th>x_12</th>\n",
       "      <th>...</th>\n",
       "      <th>x_1551</th>\n",
       "      <th>x_1552</th>\n",
       "      <th>x_1553</th>\n",
       "      <th>x_157-99</th>\n",
       "      <th>x_1571</th>\n",
       "      <th>x_1572</th>\n",
       "      <th>x_1573</th>\n",
       "      <th>x_1574</th>\n",
       "      <th>x_15710</th>\n",
       "      <th>x_15711</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7919</th>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4854</th>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10536</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x_3  x_4  x_5  x_6  x_7  x_8  x_9  x_10  x_11  x_12   ...     x_1551  \\\n",
       "1154     0    0    0    0    3    2    0     0     0     0   ...          1   \n",
       "7919   -99  -99  -99  -99  -99  -99  -99   -99   -99   -99   ...          1   \n",
       "4854   -99  -99  -99  -99  -99  -99  -99   -99   -99   -99   ...          0   \n",
       "5947     0    0    0    0    2    2    0     0     0     0   ...          1   \n",
       "10536    0    0    0    0    1    1    0     0     0     0   ...          1   \n",
       "\n",
       "       x_1552  x_1553  x_157-99  x_1571  x_1572  x_1573  x_1574  x_15710  \\\n",
       "1154        0       0         0       0       0       0       1        0   \n",
       "7919        0       0         1       0       0       0       0        0   \n",
       "4854        1       0         1       0       0       0       0        0   \n",
       "5947        0       0         1       0       0       0       0        0   \n",
       "10536       0       0         0       0       1       0       0        0   \n",
       "\n",
       "       x_15711  \n",
       "1154         0  \n",
       "7919         0  \n",
       "4854         0  \n",
       "5947         0  \n",
       "10536        0  \n",
       "\n",
       "[5 rows x 170 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "558/558 [==============================] - 1s 1ms/step - loss: 870.0071\n",
      "Epoch 2/200\n",
      "558/558 [==============================] - 0s 151us/step - loss: 862.9466\n",
      "Epoch 3/200\n",
      "558/558 [==============================] - 0s 169us/step - loss: 860.1691\n",
      "Epoch 4/200\n",
      "558/558 [==============================] - 0s 167us/step - loss: 857.8272\n",
      "Epoch 5/200\n",
      "558/558 [==============================] - 0s 138us/step - loss: 857.2383\n",
      "Epoch 6/200\n",
      "558/558 [==============================] - 0s 190us/step - loss: 857.1464\n",
      "Epoch 7/200\n",
      "558/558 [==============================] - 0s 143us/step - loss: 857.0857\n",
      "Epoch 8/200\n",
      "558/558 [==============================] - 0s 181us/step - loss: 857.0553\n",
      "Epoch 9/200\n",
      "558/558 [==============================] - 0s 190us/step - loss: 857.0290\n",
      "Epoch 10/200\n",
      "558/558 [==============================] - 0s 195us/step - loss: 856.4340\n",
      "Epoch 11/200\n",
      "558/558 [==============================] - 0s 208us/step - loss: 856.2484\n",
      "Epoch 12/200\n",
      "558/558 [==============================] - 0s 192us/step - loss: 856.1228\n",
      "Epoch 13/200\n",
      "558/558 [==============================] - 0s 163us/step - loss: 855.5743\n",
      "Epoch 14/200\n",
      "558/558 [==============================] - 0s 206us/step - loss: 855.5631\n",
      "Epoch 15/200\n",
      "558/558 [==============================] - 0s 208us/step - loss: 855.5466\n",
      "Epoch 16/200\n",
      "558/558 [==============================] - 0s 217us/step - loss: 855.5417\n",
      "Epoch 17/200\n",
      "558/558 [==============================] - 0s 215us/step - loss: 855.5372\n",
      "Epoch 18/200\n",
      "558/558 [==============================] - 0s 206us/step - loss: 855.5326\n",
      "Epoch 19/200\n",
      "558/558 [==============================] - 0s 154us/step - loss: 855.5226\n",
      "Epoch 20/200\n",
      "558/558 [==============================] - 0s 199us/step - loss: 855.5074\n",
      "Epoch 21/200\n",
      "558/558 [==============================] - 0s 194us/step - loss: 855.5036\n",
      "Epoch 22/200\n",
      "558/558 [==============================] - 0s 176us/step - loss: 855.5002\n",
      "Epoch 23/200\n",
      "558/558 [==============================] - 0s 160us/step - loss: 855.4722\n",
      "Epoch 24/200\n",
      "558/558 [==============================] - 0s 170us/step - loss: 855.4764\n",
      "Epoch 25/200\n",
      "558/558 [==============================] - 0s 174us/step - loss: 855.4705\n",
      "Epoch 26/200\n",
      "558/558 [==============================] - 0s 179us/step - loss: 855.4675\n",
      "Epoch 27/200\n",
      "558/558 [==============================] - 0s 174us/step - loss: 855.4675\n",
      "Epoch 28/200\n",
      "558/558 [==============================] - 0s 206us/step - loss: 855.4672\n",
      "Epoch 29/200\n",
      "558/558 [==============================] - 0s 203us/step - loss: 855.4650\n",
      "Epoch 30/200\n",
      "558/558 [==============================] - 0s 174us/step - loss: 855.4632\n",
      "Epoch 31/200\n",
      "558/558 [==============================] - 0s 170us/step - loss: 855.4618\n",
      "Epoch 32/200\n",
      "558/558 [==============================] - 0s 169us/step - loss: 855.4607\n",
      "Epoch 33/200\n",
      "558/558 [==============================] - 0s 197us/step - loss: 855.4596\n",
      "Epoch 34/200\n",
      "558/558 [==============================] - 0s 195us/step - loss: 855.4582\n",
      "Epoch 35/200\n",
      "558/558 [==============================] - 0s 174us/step - loss: 855.4578\n",
      "Epoch 36/200\n",
      "558/558 [==============================] - 0s 169us/step - loss: 855.4588\n",
      "Epoch 37/200\n",
      "558/558 [==============================] - 0s 165us/step - loss: 855.4572\n",
      "Epoch 38/200\n",
      "558/558 [==============================] - 0s 181us/step - loss: 855.4568\n",
      "Epoch 39/200\n",
      "558/558 [==============================] - 0s 172us/step - loss: 855.4561\n",
      "Epoch 40/200\n",
      "558/558 [==============================] - 0s 120us/step - loss: 855.4551\n",
      "Epoch 41/200\n",
      "558/558 [==============================] - 0s 151us/step - loss: 855.4545\n",
      "Epoch 42/200\n",
      "558/558 [==============================] - 0s 160us/step - loss: 855.4548\n",
      "Epoch 43/200\n",
      "558/558 [==============================] - 0s 206us/step - loss: 855.4546\n",
      "Epoch 44/200\n",
      "558/558 [==============================] - 0s 154us/step - loss: 855.4527\n",
      "Epoch 45/200\n",
      "558/558 [==============================] - 0s 152us/step - loss: 855.4532\n",
      "Epoch 46/200\n",
      "558/558 [==============================] - 0s 185us/step - loss: 855.4527\n",
      "Epoch 47/200\n",
      "558/558 [==============================] - 0s 206us/step - loss: 855.4516\n",
      "Epoch 48/200\n",
      "558/558 [==============================] - 0s 181us/step - loss: 855.4509\n",
      "Epoch 49/200\n",
      "558/558 [==============================] - 0s 199us/step - loss: 855.4493\n",
      "Epoch 50/200\n",
      "558/558 [==============================] - 0s 158us/step - loss: 855.4494\n",
      "Epoch 51/200\n",
      "558/558 [==============================] - 0s 174us/step - loss: 855.4477\n",
      "Epoch 52/200\n",
      "558/558 [==============================] - 0s 165us/step - loss: 855.4475\n",
      "Epoch 53/200\n",
      "558/558 [==============================] - 0s 126us/step - loss: 855.4475\n",
      "Epoch 54/200\n",
      "558/558 [==============================] - 0s 120us/step - loss: 855.4473\n",
      "Epoch 55/200\n",
      "558/558 [==============================] - 0s 188us/step - loss: 855.4467\n",
      "Epoch 56/200\n",
      "558/558 [==============================] - 0s 118us/step - loss: 855.4457\n",
      "Epoch 57/200\n",
      "558/558 [==============================] - 0s 122us/step - loss: 855.4453\n",
      "Epoch 58/200\n",
      "558/558 [==============================] - 0s 145us/step - loss: 855.4447\n",
      "Epoch 59/200\n",
      "558/558 [==============================] - 0s 120us/step - loss: 855.4443\n",
      "Epoch 60/200\n",
      "558/558 [==============================] - 0s 124us/step - loss: 855.4440\n",
      "Epoch 61/200\n",
      "558/558 [==============================] - 0s 147us/step - loss: 855.4443\n",
      "Epoch 62/200\n",
      "558/558 [==============================] - 0s 129us/step - loss: 855.4432\n",
      "Epoch 63/200\n",
      "558/558 [==============================] - 0s 118us/step - loss: 855.4406\n",
      "Epoch 64/200\n",
      "558/558 [==============================] - 0s 115us/step - loss: 855.4444\n",
      "Epoch 65/200\n",
      "558/558 [==============================] - 0s 118us/step - loss: 855.4437\n",
      "Epoch 66/200\n",
      "558/558 [==============================] - 0s 158us/step - loss: 855.4439\n",
      "Epoch 67/200\n",
      "558/558 [==============================] - 0s 127us/step - loss: 855.4440\n",
      "Epoch 68/200\n",
      "558/558 [==============================] - 0s 142us/step - loss: 855.4434\n",
      "Epoch 69/200\n",
      "558/558 [==============================] - 0s 120us/step - loss: 855.4435\n",
      "Epoch 70/200\n",
      "558/558 [==============================] - 0s 120us/step - loss: 855.4426\n",
      "Epoch 71/200\n",
      "558/558 [==============================] - 0s 122us/step - loss: 855.4420\n",
      "Epoch 72/200\n",
      "558/558 [==============================] - 0s 111us/step - loss: 855.4418\n",
      "Epoch 73/200\n",
      "558/558 [==============================] - 0s 120us/step - loss: 855.4409\n",
      "Epoch 74/200\n",
      "558/558 [==============================] - 0s 120us/step - loss: 855.4408\n",
      "Epoch 75/200\n",
      "558/558 [==============================] - 0s 115us/step - loss: 855.4405\n",
      "Epoch 76/200\n",
      "558/558 [==============================] - 0s 129us/step - loss: 855.4416\n",
      "Epoch 77/200\n",
      "558/558 [==============================] - 0s 120us/step - loss: 855.4410\n",
      "Epoch 78/200\n",
      "558/558 [==============================] - 0s 122us/step - loss: 855.4406\n",
      "Epoch 79/200\n",
      "558/558 [==============================] - 0s 122us/step - loss: 855.4403\n",
      "Epoch 80/200\n",
      "558/558 [==============================] - 0s 115us/step - loss: 855.4404\n",
      "Epoch 81/200\n",
      "558/558 [==============================] - 0s 111us/step - loss: 855.4400\n",
      "Epoch 82/200\n",
      "558/558 [==============================] - 0s 122us/step - loss: 855.4398\n",
      "Epoch 83/200\n",
      "558/558 [==============================] - 0s 117us/step - loss: 855.4392\n",
      "Epoch 84/200\n",
      "558/558 [==============================] - 0s 111us/step - loss: 855.4389\n",
      "Epoch 85/200\n",
      "558/558 [==============================] - 0s 118us/step - loss: 855.4393\n",
      "Epoch 86/200\n",
      "558/558 [==============================] - 0s 111us/step - loss: 855.4389\n",
      "Epoch 87/200\n",
      "558/558 [==============================] - 0s 122us/step - loss: 855.4384\n",
      "Epoch 88/200\n",
      "558/558 [==============================] - 0s 122us/step - loss: 855.4378\n",
      "Epoch 89/200\n",
      "558/558 [==============================] - 0s 118us/step - loss: 855.4359\n",
      "Epoch 90/200\n",
      "558/558 [==============================] - 0s 120us/step - loss: 855.4327\n",
      "Epoch 91/200\n",
      "558/558 [==============================] - 0s 115us/step - loss: 855.4277\n",
      "Epoch 92/200\n",
      "558/558 [==============================] - 0s 133us/step - loss: 855.4238\n",
      "Epoch 93/200\n",
      "558/558 [==============================] - 0s 115us/step - loss: 855.4223\n",
      "Epoch 94/200\n",
      "558/558 [==============================] - 0s 115us/step - loss: 855.4217\n",
      "Epoch 95/200\n",
      "558/558 [==============================] - 0s 106us/step - loss: 855.4214\n",
      "Epoch 96/200\n",
      "558/558 [==============================] - 0s 124us/step - loss: 855.4212\n",
      "Epoch 97/200\n",
      "558/558 [==============================] - 0s 118us/step - loss: 855.4209\n",
      "Epoch 98/200\n",
      "558/558 [==============================] - 0s 117us/step - loss: 855.4207\n",
      "Epoch 99/200\n",
      "558/558 [==============================] - 0s 109us/step - loss: 855.4199\n",
      "Epoch 100/200\n",
      "558/558 [==============================] - 0s 124us/step - loss: 855.4176\n",
      "Epoch 101/200\n",
      "558/558 [==============================] - 0s 133us/step - loss: 855.4170\n",
      "Epoch 102/200\n",
      "558/558 [==============================] - 0s 126us/step - loss: 855.4173\n",
      "Epoch 103/200\n",
      "558/558 [==============================] - 0s 118us/step - loss: 855.4172\n",
      "Epoch 104/200\n",
      "558/558 [==============================] - 0s 122us/step - loss: 855.4165\n",
      "Epoch 105/200\n",
      "558/558 [==============================] - 0s 129us/step - loss: 855.4162\n",
      "Epoch 106/200\n",
      "558/558 [==============================] - 0s 129us/step - loss: 855.4157\n",
      "Epoch 107/200\n",
      "558/558 [==============================] - 0s 134us/step - loss: 855.4148\n",
      "Epoch 108/200\n",
      "558/558 [==============================] - 0s 124us/step - loss: 855.4128\n",
      "Epoch 109/200\n",
      "558/558 [==============================] - 0s 134us/step - loss: 855.4123\n",
      "Epoch 110/200\n",
      "558/558 [==============================] - 0s 124us/step - loss: 855.4119\n",
      "Epoch 111/200\n",
      "558/558 [==============================] - 0s 126us/step - loss: 855.4118\n",
      "Epoch 112/200\n",
      "558/558 [==============================] - 0s 124us/step - loss: 855.4135\n",
      "Epoch 113/200\n",
      "558/558 [==============================] - 0s 122us/step - loss: 855.4131\n",
      "Epoch 114/200\n",
      "558/558 [==============================] - 0s 127us/step - loss: 855.4127\n",
      "Epoch 115/200\n",
      "558/558 [==============================] - 0s 122us/step - loss: 855.4116\n",
      "Epoch 116/200\n",
      "558/558 [==============================] - 0s 118us/step - loss: 855.4119\n",
      "Epoch 117/200\n",
      "558/558 [==============================] - 0s 118us/step - loss: 855.4115\n",
      "Epoch 118/200\n",
      "558/558 [==============================] - 0s 118us/step - loss: 855.4111\n",
      "Epoch 119/200\n",
      "558/558 [==============================] - 0s 113us/step - loss: 855.4115\n",
      "Epoch 120/200\n",
      "558/558 [==============================] - 0s 120us/step - loss: 855.4114\n",
      "Epoch 121/200\n",
      "558/558 [==============================] - 0s 127us/step - loss: 855.4108\n",
      "Epoch 122/200\n",
      "558/558 [==============================] - 0s 127us/step - loss: 855.4104\n",
      "Epoch 123/200\n",
      "558/558 [==============================] - 0s 118us/step - loss: 855.4104\n",
      "Epoch 124/200\n",
      "558/558 [==============================] - 0s 117us/step - loss: 855.4100\n",
      "Epoch 125/200\n",
      "558/558 [==============================] - 0s 120us/step - loss: 855.4093\n",
      "Epoch 126/200\n",
      "558/558 [==============================] - 0s 122us/step - loss: 855.4086\n",
      "Epoch 127/200\n",
      "558/558 [==============================] - 0s 113us/step - loss: 855.4102\n",
      "Epoch 128/200\n",
      "558/558 [==============================] - 0s 120us/step - loss: 855.4097\n",
      "Epoch 129/200\n",
      "558/558 [==============================] - 0s 126us/step - loss: 855.4097\n",
      "Epoch 130/200\n",
      "558/558 [==============================] - 0s 126us/step - loss: 855.4095\n",
      "Epoch 131/200\n",
      "558/558 [==============================] - 0s 120us/step - loss: 855.4094\n",
      "Epoch 132/200\n",
      "558/558 [==============================] - 0s 129us/step - loss: 855.4093\n",
      "Epoch 133/200\n",
      "558/558 [==============================] - 0s 131us/step - loss: 855.4092\n",
      "Epoch 134/200\n",
      "558/558 [==============================] - 0s 122us/step - loss: 855.4094\n",
      "Epoch 135/200\n",
      "558/558 [==============================] - 0s 127us/step - loss: 855.4092\n",
      "Epoch 136/200\n",
      "558/558 [==============================] - 0s 133us/step - loss: 855.4093\n",
      "Epoch 137/200\n",
      "558/558 [==============================] - 0s 136us/step - loss: 855.4088\n",
      "Epoch 138/200\n",
      "558/558 [==============================] - 0s 143us/step - loss: 855.4088\n",
      "Epoch 139/200\n",
      "558/558 [==============================] - 0s 127us/step - loss: 855.4084\n",
      "Epoch 140/200\n",
      "558/558 [==============================] - 0s 134us/step - loss: 855.4081\n",
      "Epoch 141/200\n",
      "558/558 [==============================] - 0s 172us/step - loss: 855.4080\n",
      "Epoch 142/200\n",
      "558/558 [==============================] - 0s 190us/step - loss: 855.4079\n",
      "Epoch 143/200\n",
      "558/558 [==============================] - 0s 262us/step - loss: 855.4083\n",
      "Epoch 144/200\n",
      "558/558 [==============================] - 0s 178us/step - loss: 855.4081\n",
      "Epoch 145/200\n",
      "558/558 [==============================] - 0s 149us/step - loss: 855.4083\n",
      "Epoch 146/200\n",
      "558/558 [==============================] - 0s 143us/step - loss: 855.4081\n",
      "Epoch 147/200\n",
      "558/558 [==============================] - 0s 140us/step - loss: 855.4077\n",
      "Epoch 148/200\n",
      "558/558 [==============================] - 0s 143us/step - loss: 855.4078\n",
      "Epoch 149/200\n",
      "558/558 [==============================] - 0s 134us/step - loss: 855.4076\n",
      "Epoch 150/200\n",
      "558/558 [==============================] - 0s 127us/step - loss: 855.4074\n",
      "Epoch 151/200\n",
      "558/558 [==============================] - 0s 124us/step - loss: 855.4073\n",
      "Epoch 152/200\n",
      "558/558 [==============================] - 0s 122us/step - loss: 855.4071\n",
      "Epoch 153/200\n",
      "558/558 [==============================] - 0s 120us/step - loss: 855.4074\n",
      "Epoch 154/200\n",
      "558/558 [==============================] - 0s 138us/step - loss: 855.4077\n",
      "Epoch 155/200\n",
      "558/558 [==============================] - 0s 131us/step - loss: 855.4073\n",
      "Epoch 156/200\n",
      "558/558 [==============================] - 0s 131us/step - loss: 855.4069\n",
      "Epoch 157/200\n",
      "558/558 [==============================] - 0s 131us/step - loss: 855.4068\n",
      "Epoch 158/200\n",
      "558/558 [==============================] - 0s 138us/step - loss: 855.4065\n",
      "Epoch 159/200\n",
      "558/558 [==============================] - 0s 124us/step - loss: 855.4068\n",
      "Epoch 160/200\n",
      "558/558 [==============================] - 0s 122us/step - loss: 855.4066\n",
      "Epoch 161/200\n",
      "558/558 [==============================] - 0s 118us/step - loss: 855.4063\n",
      "Epoch 162/200\n",
      "558/558 [==============================] - 0s 129us/step - loss: 855.4064\n",
      "Epoch 163/200\n",
      "558/558 [==============================] - 0s 129us/step - loss: 855.4064\n",
      "Epoch 164/200\n",
      "558/558 [==============================] - 0s 118us/step - loss: 855.4064\n",
      "Epoch 165/200\n",
      "558/558 [==============================] - 0s 122us/step - loss: 855.4062\n",
      "Epoch 166/200\n",
      "558/558 [==============================] - 0s 118us/step - loss: 855.4054\n",
      "Epoch 167/200\n",
      "558/558 [==============================] - 0s 117us/step - loss: 855.4048\n",
      "Epoch 168/200\n",
      "558/558 [==============================] - 0s 117us/step - loss: 855.4043\n",
      "Epoch 169/200\n",
      "558/558 [==============================] - 0s 126us/step - loss: 855.4044\n",
      "Epoch 170/200\n",
      "558/558 [==============================] - 0s 120us/step - loss: 855.4047\n",
      "Epoch 171/200\n",
      "558/558 [==============================] - 0s 120us/step - loss: 855.4047\n",
      "Epoch 172/200\n",
      "558/558 [==============================] - 0s 118us/step - loss: 855.4046\n",
      "Epoch 173/200\n",
      "558/558 [==============================] - 0s 120us/step - loss: 855.4042\n",
      "Epoch 174/200\n",
      "558/558 [==============================] - 0s 129us/step - loss: 855.4048\n",
      "Epoch 175/200\n",
      "558/558 [==============================] - 0s 122us/step - loss: 855.4046\n",
      "Epoch 176/200\n",
      "558/558 [==============================] - 0s 122us/step - loss: 855.4044\n",
      "Epoch 177/200\n",
      "558/558 [==============================] - 0s 122us/step - loss: 855.4041\n",
      "Epoch 178/200\n",
      "558/558 [==============================] - 0s 129us/step - loss: 855.4033\n",
      "Epoch 179/200\n",
      "558/558 [==============================] - 0s 113us/step - loss: 855.4036\n",
      "Epoch 180/200\n",
      "558/558 [==============================] - 0s 117us/step - loss: 855.4036\n",
      "Epoch 181/200\n",
      "558/558 [==============================] - 0s 118us/step - loss: 855.4039\n",
      "Epoch 182/200\n",
      "558/558 [==============================] - 0s 122us/step - loss: 855.4041\n",
      "Epoch 183/200\n",
      "558/558 [==============================] - 0s 118us/step - loss: 855.4044\n",
      "Epoch 184/200\n",
      "558/558 [==============================] - 0s 118us/step - loss: 855.4037\n",
      "Epoch 185/200\n",
      "558/558 [==============================] - 0s 120us/step - loss: 855.4041\n",
      "Epoch 186/200\n",
      "558/558 [==============================] - 0s 117us/step - loss: 855.4038\n",
      "Epoch 187/200\n",
      "558/558 [==============================] - 0s 120us/step - loss: 855.4032\n",
      "Epoch 188/200\n",
      "558/558 [==============================] - 0s 118us/step - loss: 855.4030\n",
      "Epoch 189/200\n",
      "558/558 [==============================] - 0s 120us/step - loss: 855.4031\n",
      "Epoch 190/200\n",
      "558/558 [==============================] - 0s 120us/step - loss: 855.4030\n",
      "Epoch 191/200\n",
      "558/558 [==============================] - 0s 124us/step - loss: 855.4025\n",
      "Epoch 192/200\n",
      "558/558 [==============================] - 0s 118us/step - loss: 855.4024\n",
      "Epoch 193/200\n",
      "558/558 [==============================] - 0s 138us/step - loss: 855.4021\n",
      "Epoch 194/200\n",
      "558/558 [==============================] - 0s 147us/step - loss: 855.4027\n",
      "Epoch 195/200\n",
      "558/558 [==============================] - 0s 127us/step - loss: 855.4023\n",
      "Epoch 196/200\n",
      "558/558 [==============================] - 0s 122us/step - loss: 855.4018\n",
      "Epoch 197/200\n",
      "558/558 [==============================] - 0s 129us/step - loss: 855.4023\n",
      "Epoch 198/200\n",
      "558/558 [==============================] - 0s 122us/step - loss: 855.4018\n",
      "Epoch 199/200\n",
      "558/558 [==============================] - 0s 131us/step - loss: 855.4016\n",
      "Epoch 200/200\n",
      "558/558 [==============================] - 0s 124us/step - loss: 855.4017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c25d142d30>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 压缩特征维度至2维\n",
    "encoding_dim = 16\n",
    " \n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(170,))\n",
    " \n",
    "# 编码层\n",
    "encoded = Dense(128, activation='relu')(input_img)\n",
    "# encoded = Dense(64, activation='relu')(encoded)\n",
    "# encoded = Dense(32, activation='relu')(encoded)\n",
    "encoder_output = Dense(encoding_dim)(encoded)\n",
    "\n",
    "# 解码层\n",
    "decoded = Dense(128, activation='relu')(encoder_output)\n",
    "# decoded = Dense(64, activation='relu')(decoded)\n",
    "# decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(170, activation='tanh')(decoded)\n",
    " \n",
    "# 构建自编码模型\n",
    "autoencoder = Model(inputs=input_img, outputs=decoded)\n",
    " \n",
    "# 构建编码模型\n",
    "encoder = Model(inputs=input_img, outputs=encoder_output)\n",
    " \n",
    "# compile autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# training\n",
    "autoencoder.fit(train_data1.values, train_data1.values, epochs=200, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa = train_data.iloc[0:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aaa = train_data1.iloc[0:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bb = autoencoder.predict(aa.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bbb = autoencoder.predict(aaa.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 170)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170,)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170,)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.460848536087086\n",
      "2094.46020928661\n",
      "2266.610818114318\n",
      "226.30304847160147\n",
      "170.59625352317065\n",
      "66.11220982358239\n",
      "1079.9721744945496\n",
      "226.84798552281376\n",
      "1027.1385578393295\n",
      "1191.553959535359\n",
      "114.02607635342002\n",
      "172.62573543260248\n",
      "170.3938392196973\n",
      "5.456969119276675\n",
      "2208.6225343944257\n",
      "172.50192837675698\n",
      "2040.7565252741415\n",
      "2208.2765864004673\n",
      "1192.3076903558529\n",
      "2206.6924110954824\n",
      "2041.4469694987934\n",
      "173.07057502104576\n",
      "171.9875910816681\n",
      "62.50445356124677\n",
      "181.30818638383687\n",
      "9.137724336126103\n",
      "175.25587692280666\n",
      "2263.0457764991743\n",
      "60.766524227371434\n",
      "2207.297734945301\n",
      "2210.483762478653\n",
      "1190.0468305487354\n",
      "2262.5044827354986\n",
      "173.1487106636279\n",
      "1079.873012855182\n",
      "65.31651244647227\n",
      "2262.8056334531307\n",
      "175.4847944222441\n",
      "2263.210745332828\n",
      "2042.4301913324953\n",
      "59.777956638954194\n",
      "2322.108287436209\n",
      "231.34011182245027\n",
      "1254.5436818759229\n",
      "2209.3341958071715\n",
      "2038.2708228770896\n",
      "172.23537620146988\n",
      "2207.674868446342\n",
      "2206.50959232615\n",
      "2265.5641012078045\n",
      "2263.269166383738\n",
      "227.0191575369463\n",
      "2041.0476198151637\n",
      "2262.933928819217\n",
      "3.5212105741072848\n",
      "170.8049733443256\n",
      "1243.961996479481\n",
      "2322.2236513160665\n",
      "174.45283606685584\n",
      "284.79036066088406\n",
      "66.4320784720436\n",
      "2209.3283980582814\n",
      "3.9844601925232843\n",
      "172.5231034434841\n",
      "2097.61542463699\n",
      "2041.5744366787806\n",
      "170.19439061131717\n",
      "2211.2761235022476\n",
      "174.48452091038453\n",
      "7.704202188376882\n",
      "2101.104990737724\n",
      "58.28554280331611\n",
      "229.9045532365384\n",
      "2207.5512261791364\n",
      "2095.512630564972\n",
      "231.2408959181288\n",
      "226.74936688846282\n",
      "179.88379563590138\n",
      "2208.640294720187\n",
      "1192.9828399762905\n",
      "2040.587600029207\n",
      "2263.133445015679\n",
      "234.33192710566013\n",
      "2150.529738485155\n",
      "2264.740411891873\n",
      "2096.066181655967\n",
      "3.316089597995368\n",
      "172.34224550094058\n",
      "2266.216869485175\n",
      "175.80839424951236\n",
      "2095.230849887617\n",
      "2208.0462934616726\n",
      "5.460751400027132\n",
      "230.20465823662033\n",
      "2209.822021457822\n",
      "178.79836494382053\n",
      "2043.4942378850008\n",
      "175.73009085579704\n",
      "228.0794833368176\n",
      "63.80791161494981\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "for i in range(100):\n",
    "    print(mean_squared_error(aa.values[i], bb[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226.66258008639403\n",
      "228.36058144617203\n",
      "2263.445611987434\n",
      "170.8135173061272\n",
      "2319.6719606686343\n",
      "284.2247373840772\n",
      "172.1715234441927\n",
      "176.35257216007946\n",
      "172.74146986661535\n",
      "170.72351606254256\n",
      "1195.2421197586618\n",
      "226.31531888210148\n",
      "2208.713442336666\n",
      "2262.951614398245\n",
      "1020.3931955909478\n",
      "6.357930202689379\n",
      "2042.806279741908\n",
      "170.27680699118687\n",
      "2207.051646613859\n",
      "2262.860400345776\n",
      "227.10392478625582\n",
      "8.486017595630054\n",
      "226.26966899502747\n",
      "282.85002911112986\n",
      "171.865212458618\n",
      "1192.3103598704568\n",
      "2263.5988518190297\n",
      "226.37516889428102\n",
      "172.95597887863877\n",
      "176.74995345756724\n",
      "284.2118457189799\n",
      "232.73246866671448\n",
      "172.98647890731218\n",
      "174.48907108059734\n",
      "226.60783340183562\n",
      "284.6216869403274\n",
      "285.0826488067991\n",
      "227.3758301284358\n",
      "2206.9280976257987\n",
      "284.5230560295343\n",
      "1079.4194418727063\n",
      "175.17214033628707\n",
      "172.5947498714444\n",
      "226.71525210998337\n",
      "58.43459729320334\n",
      "58.126637023245785\n",
      "4712.101187286687\n",
      "227.6036045265542\n",
      "228.0342860868576\n",
      "2263.194608905707\n",
      "227.12561408767374\n",
      "172.803233152875\n",
      "1196.0228331513222\n",
      "2265.4807845664086\n",
      "283.45367713384593\n",
      "227.6501634651584\n",
      "226.2983362182201\n",
      "2266.4809595773077\n",
      "169.78304917306417\n",
      "227.31508525361582\n",
      "228.42032869325442\n",
      "227.01500072823768\n",
      "2210.4759381617587\n",
      "226.71399087654186\n",
      "58.20857538268314\n",
      "232.86292592549063\n",
      "284.21451392100744\n",
      "234.12104494436085\n",
      "2263.322229270376\n",
      "1194.3532498291165\n",
      "226.53885787575118\n",
      "175.49603640764607\n",
      "226.46146190207168\n",
      "227.42024980399083\n",
      "230.9073788533334\n",
      "2263.3456913607592\n",
      "2263.386511428877\n",
      "171.80051425313997\n",
      "171.84290578958286\n",
      "226.67802263347133\n",
      "226.44969998781667\n",
      "2263.080983852972\n",
      "178.05353378369247\n",
      "59.97713179382162\n",
      "226.39094049483967\n",
      "227.64954055002096\n",
      "228.62451185516323\n",
      "2262.3754417195396\n",
      "226.6795165450307\n",
      "229.47338205574817\n",
      "226.56434839909338\n",
      "1243.9679591908398\n",
      "175.95563252084546\n",
      "173.6339869199538\n",
      "227.20246348058342\n",
      "2209.0459092575443\n",
      "170.52736354652833\n",
      "2206.745779836676\n",
      "2263.6930780507673\n",
      "227.57895692091182\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(mean_squared_error(aaa.values[i], bbb[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
